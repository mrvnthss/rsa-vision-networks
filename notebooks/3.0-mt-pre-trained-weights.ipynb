{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e17b36d-5c59-4b7b-a5f8-46eadc943bd9",
   "metadata": {},
   "source": [
    "# Using Pre-Trained Weights\n",
    "\n",
    "https://pytorch.org/vision/stable/models.html  \n",
    "https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights  \n",
    "https://pytorch.org/vision/stable/_modules/torchvision/models/_api.html  \n",
    "https://github.com/pytorch/vision/blob/main/torchvision/transforms/_presets.py\n",
    "\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b331cb5-908e-4ad8-9eef-37a8d1f881d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.848677Z",
     "start_time": "2024-05-14T09:00:23.125757Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d26ea6-9460-483a-8bcb-f35cedca0a8e",
   "metadata": {},
   "source": [
    "## Available Models\n",
    "\n",
    "https://pytorch.org/vision/stable/generated/torchvision.models.list_models.html\n",
    "\n",
    "The `list_models()` function can be used to list all available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a23ab8-879a-4bda-81a1-aedbfbc28882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.851323Z",
     "start_time": "2024-05-14T09:00:26.849508Z"
    }
   },
   "outputs": [],
   "source": [
    "for model in models.list_models():\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0cfd35-ae65-4557-960c-a883653f9e66",
   "metadata": {},
   "source": [
    "**Filters** can be used to narrow down the list of available models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0771d42-dd83-43f4-af0e-b082811eca3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.853827Z",
     "start_time": "2024-05-14T09:00:26.851952Z"
    }
   },
   "outputs": [],
   "source": [
    "# VGG models\n",
    "vgg_models = models.list_models(include=\"vgg*\")\n",
    "print(\"ALL VGG MODELS:\")\n",
    "for model in vgg_models:\n",
    "    print(model)\n",
    "\n",
    "# VGG models that do not use batch normalization\n",
    "vgg_models = models.list_models(include=\"vgg*\", exclude=\"*bn\")\n",
    "print(\"\\nVGG MODELS WITHOUT BATCH NORMALIZATION:\")\n",
    "for model in vgg_models:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828fcfd8-f4da-4aed-8561-ad89487301b8",
   "metadata": {},
   "source": [
    "## Pre-Trained Weights\n",
    "\n",
    "* Available classification weights: https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights\n",
    "* `get_model_weights()` function: https://pytorch.org/vision/stable/generated/torchvision.models.get_model_weights.html\n",
    "* `get_weight()` function: https://pytorch.org/vision/stable/generated/torchvision.models.get_weight.html\n",
    "\n",
    "\n",
    "\n",
    "### Technical Details\n",
    "\n",
    "The `get_model_weights()` function can be used to obtain all available weights. The function has return type  \n",
    "`Type[WeightsEnum]`, i.e., it returns the weights enum **class** of the associated model (not an instance of that class). The  \n",
    "`WeightsEnum` class defined [here](https://pytorch.org/vision/main/_modules/torchvision/models/_api.html) inherits from Python's built-in `Enum` base class for creating enumerated constants, see [here](https://docs.python.org/3/library/enum.html)  \n",
    "and [here](https://docs.python.org/3/howto/enum.html#enum-basic-tutorial) for details. This class represents the different pre-trained weights that are available for the given model. Each member  \n",
    "of this enumeration is a unique instance of this class, representing a specific set of pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e102608c-d94d-4621-9c78-e0a023579aa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.856464Z",
     "start_time": "2024-05-14T09:00:26.854775Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_enum = models.get_model_weights(\"resnet50\")\n",
    "print(weights_enum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9249c283-1930-4410-ad8e-9bd135d138af",
   "metadata": {},
   "source": [
    "We can list all available weights for a given model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fed7071-576a-494c-8934-a840a8aba545",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.858448Z",
     "start_time": "2024-05-14T09:00:26.856942Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"AVAILABLE RESNET-50 WEIGHTS:\")\n",
    "for weights in weights_enum:\n",
    "    print(f\"{weights.name}: {weights}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d74b3bd-5105-41ac-9171-b8ff0af31633",
   "metadata": {},
   "source": [
    "The `weights_enum` is an enumeration with as many members as there are available pre-trained weights for a given model. Each  \n",
    "**member** is technically an **attribute** of `weights_enum`, allowing us to access them as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a046f0-aa85-40a1-b378-efc27c3ea0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.860516Z",
     "start_time": "2024-05-14T09:00:26.859008Z"
    }
   },
   "outputs": [],
   "source": [
    "# ImageNet weights (old version)\n",
    "print(weights_enum.IMAGENET1K_V1)\n",
    "\n",
    "# ImageNet weights (new version)\n",
    "print(weights_enum.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088ff9f-77d0-4f66-bcf9-19451d45645e",
   "metadata": {},
   "source": [
    "We can also access the individual members as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ca5d3-12af-4d0e-93df-97f9b99a7357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.862391Z",
     "start_time": "2024-05-14T09:00:26.861029Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet50_weights_v2 = weights_enum[\"IMAGENET1K_V2\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7059f234-a704-4114-91f9-a43a4bb0bdb9",
   "metadata": {},
   "source": [
    "Each member has a `name` and a `value` associated with it. The `name` of a member is what we just used to access the member in  \n",
    "the previous line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2b12ca-7337-4976-a55a-94f1d081eb17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.864253Z",
     "start_time": "2024-05-14T09:00:26.862798Z"
    }
   },
   "outputs": [],
   "source": [
    "print(resnet50_weights_v2.name == \"IMAGENET1K_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d67858-6613-445a-9626-99314d9afd60",
   "metadata": {},
   "source": [
    "As stated earlier, `weights_enum` is the `WeightsEnum` **class** associated with a given model, and its members/attributes are  \n",
    "**instances** of that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e92dd34-6706-4f51-b866-d5ade40b7ce6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.867435Z",
     "start_time": "2024-05-14T09:00:26.864737Z"
    }
   },
   "outputs": [],
   "source": [
    "print(type(resnet50_weights_v2))\n",
    "isinstance(resnet50_weights_v2, weights_enum)  # members are instances of the WeightsEnum class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e781440-f45e-45c8-995e-a6c96a62e4a1",
   "metadata": {},
   "source": [
    "Finally, the **value** of each member is an instance of the `Weights` class defined in `torchvision.models._api`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e7a0e-c661-4520-89e4-0e521bf71a7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.870591Z",
     "start_time": "2024-05-14T09:00:26.868943Z"
    }
   },
   "outputs": [],
   "source": [
    "type(resnet50_weights_v2.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b82fe-99c2-48fb-a916-2512d1e7ec4b",
   "metadata": {},
   "source": [
    "**To sum up**:\n",
    "\n",
    "* The `get_model_weights()` function returns the weights enum class associated with the given model. This `WeightsEnum`  \n",
    "  class inherits from `enum.Enum`, and is an **enumeration** of all the pre-trained weights available for a model.\n",
    "* The **attributes** of that class are **enumeration members**, and are functionally constants.\n",
    "* Each member has a **name** and **value** associated with it.\n",
    "* The **value** of each member inherits from the `Weights` class defined in `torchvision.models._api`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bb071-8029-48a2-aa71-f52377a2dec7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.872589Z",
     "start_time": "2024-05-14T09:00:26.871045Z"
    }
   },
   "outputs": [],
   "source": [
    "weights_enum = models.get_model_weights(\"resnet50\")  # weights enum class associated with ResNet-50 (enumeration)\n",
    "resnet50_weights_v2 = weights_enum.IMAGENET1K_V2     # member of the enumeration\n",
    "print(type(resnet50_weights_v2.value))               # the actual weights (instance of class `Weights`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bec592-ae01-4630-b832-409e793ec687",
   "metadata": {},
   "source": [
    "Finally, it is also possible to directly access a **particular instance** of the weights enum class of a given model using the  \n",
    "`get_weight()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190e5412-4159-4529-a3f0-7fb539091feb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-14T09:00:26.875084Z",
     "start_time": "2024-05-14T09:00:26.873069Z"
    }
   },
   "outputs": [],
   "source": [
    "models.get_model_weights(\"resnet50\")[\"IMAGENET1K_V2\"] == models.get_weight(\"ResNet50_Weights.IMAGENET1K_V2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d21b75-ebbe-4e2a-912c-7532a49a7304",
   "metadata": {},
   "source": [
    "All available pre-trained weights are listed [here](https://pytorch.org/vision/stable/models.html#table-of-all-available-classification-weights).\n",
    "\n",
    "\n",
    "### Working with Pre-Trained Weights\n",
    "\n",
    "Each set of pre-trained weights is an instance of the `Weights` class introduced in `torchvision.models._api` (see [here](https://pytorch.org/vision/main/_modules/torchvision/models/_api.html)).  \n",
    "As such, the following useful properties and methods are available:\n",
    "\n",
    "* `.url`: Returns the **url** from which the pre-trained weights can be downloaded.\n",
    "* `.meta`: Returns a `Dict[str, Any]` containing useful metadata about the pre-trained weights, such as **categories** (of the  \n",
    "  classification task), the **number of parameters**, and the **training recipe**.\n",
    "* `.transforms`: Returns the **preprocessing transforms** to be used when working with the pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76025c21-3c10-4231-8728-3d318df02063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get weights enum for VGG11\n",
    "vgg11_weights = models.get_weight(\"VGG11_Weights.IMAGENET1K_V1\")\n",
    "\n",
    "# URL to download weights\n",
    "print(f\"URL:\\n{vgg11_weights.url}\\n\")\n",
    "\n",
    "# Keys of the dictionary returned by `.dict`\n",
    "print(\"KEYS IN META DICT:\")\n",
    "for k in vgg11_weights.meta:\n",
    "    print(k)\n",
    "\n",
    "# File size of model weights\n",
    "print(f\"\\nFILE SIZE:\\n{vgg11_weights.meta['_file_size']} MB\")\n",
    "\n",
    "# Link to training recipe extracted from dict returned by `.meta`\n",
    "print(f\"\\nTRAINING RECIPE:\\n{vgg11_weights.meta['recipe']}\")\n",
    "\n",
    "# Preprocessing transforms\n",
    "print(f\"\\nPREPROCESSING TRANSFORMS:\\n{vgg11_weights.transforms()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228dfbaa-9fd2-4438-8781-9357fd21c675",
   "metadata": {},
   "source": [
    "**NOTE**: The **_V2** weights improve upon the results of the original paper by using TorchVision’s [new training recipe](https://pytorch.org/blog/how-to-train-state-of-the-art-models-using-torchvision-latest-primitives/).\n",
    "\n",
    "To obtain the checkpoint storing the pre-trained weights, we can use the `get_state_dict()` method. This **downloads** the  \n",
    "checkpoint and **loads** the state dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8175ae-4382-46fc-8b55-603b47996194",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11_weights_dict = vgg11_weights.get_state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac98fa3-1fcb-4c41-97b2-c1c958151dca",
   "metadata": {},
   "source": [
    "Let's take a look at the keys of the ordered dict `vgg11_weights_dict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc31754-c952-4d43-903c-45c741bf6d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in vgg11_weights_dict:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e52fe2-0c2a-4ee7-9e95-a10651112a9b",
   "metadata": {},
   "source": [
    "To illustrate how to use these weights, let's implement VGG11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875de0ef-0a92-44f5-9323-2dead0858de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11 = models.vgg11()\n",
    "print(vgg11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0a05a-fc8d-429a-b457-9a9b42200f81",
   "metadata": {},
   "source": [
    "As we can see, each entry in the `vgg11_weights_dict` corresponds to a layer of VGG11 with trainable parameters.  Also, we can  \n",
    "retreive **only** those **layers with trainable parameters** as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd4f8ab-f11c-4b28-a791-9bc128e72ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in vgg11.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bbd737-db33-4078-bd67-83c8b62f73dc",
   "metadata": {},
   "source": [
    "Since we didn't specify any weights when initializing the network, the weights were initialized randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187674fa-4464-4047-8629-e4929a9a372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Shape identical: \"\n",
    "    f\"{vgg11.state_dict()['features.0.weight'].size() == vgg11_weights_dict['features.0.weight'].size()}\"\n",
    ")\n",
    "print(\n",
    "    \"Weights identical: \"\n",
    "    f\"{torch.all(vgg11.state_dict()['features.0.weight'] == vgg11_weights_dict['features.0.weight'])}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8e356-dbde-4973-83b9-d75b1d5249b8",
   "metadata": {},
   "source": [
    "Assigning pre-trained weights to **individual layers** is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7d110c-86d5-4254-88d1-f67e712c6627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign weights to first convolutional layer\n",
    "vgg11.features[0].weight.data = vgg11_weights_dict[\"features.0.weight\"]\n",
    "\n",
    "# Check whether weights have successfully been assigned\n",
    "print(\n",
    "    \"Weights identical: \"\n",
    "    f\"{torch.all(vgg11.state_dict()['features.0.weight'] == vgg11_weights_dict['features.0.weight'])}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
