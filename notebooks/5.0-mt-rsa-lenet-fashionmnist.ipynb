{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6332472b-7f65-4564-8421-45139c638827",
   "metadata": {},
   "source": [
    "# RSA: LeNet-5 x FashionMNIST\n",
    "\n",
    "*Version History*\n",
    "\n",
    "* **5.0** - Check functionality of ``RepresentationalSimilarityTrainer`` and RSA functions via test run\n",
    "\n",
    "\n",
    "## Preparation\n",
    "\n",
    "\n",
    "### Imports & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e0a534-9eaa-41b7-8d8f-edec5d694978",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T11:51:44.551856Z",
     "start_time": "2024-09-10T11:51:43.027043Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import Any, Callable, Dict, Literal, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from torch import linalg as LA\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchmetrics import MetricCollection\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "\n",
    "from src.base_classes.base_loader import BaseLoader\n",
    "from src.datasets.fashionmnist import FashionMNIST\n",
    "from src.models.lenet import LeNet\n",
    "from src.training.representational_similarity_trainer import RepresentationalSimilarityTrainer\n",
    "from src.utils.classification_presets import ClassificationPresets\n",
    "from src.utils.utils import evaluate_classifier\n",
    "\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = \"../data\"\n",
    "CHKPT_PATH = \"../models/lenet_fashionmnist.pt\"\n",
    "\n",
    "# Seeds\n",
    "TORCH_SEED = 89\n",
    "SHUFFLE_SEED = 858\n",
    "SPLIT_SEED = 42\n",
    "\n",
    "# Dataloader\n",
    "VAL_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "# Training\n",
    "DEVICE = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b98209-ddc0-407a-b8d3-1665132e0faa",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "* ``get_timestamp`` &rarr; Get a timestamp of the current date and time.\n",
    "* ``set_seeds`` &rarr; Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27e6a2c0-236d-4e26-a69c-94355567e156",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamp() -> str:\n",
    "    \"\"\"Get a timestamp of the current date and time.\"\"\"\n",
    "    \n",
    "    return datetime.now().strftime(\"%Y-%m_%d-%H-%M-%S\")\n",
    "\n",
    "\n",
    "def set_seeds() -> None:\n",
    "    \"\"\"Set random seeds for reproducibility.\"\"\"\n",
    "    \n",
    "    random.seed(TORCH_SEED)\n",
    "    np.random.seed(TORCH_SEED)\n",
    "    torch.manual_seed(TORCH_SEED)\n",
    "    torch.cuda.manual_seed_all(TORCH_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf59b1d-3d31-4ad1-a71c-7e89c30b67f1",
   "metadata": {},
   "source": [
    "### FashionMNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54eac8b5-13fd-4709-b94a-91020acce97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T11:51:51.358704Z",
     "start_time": "2024-09-10T11:51:44.557393Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                           \r"
     ]
    }
   ],
   "source": [
    "# Prepare transforms\n",
    "train_transform = ClassificationPresets(\n",
    "    mean=[0.2860],\n",
    "    std=[0.3205],\n",
    "    crop_size=32,\n",
    "    crop_scale=(0.8, 0.8),\n",
    "    crop_ratio=(1, 1),\n",
    "    flip_prob=0.5\n",
    ")\n",
    "\n",
    "val_transform = ClassificationPresets(\n",
    "    mean=[0.2860],\n",
    "    std=[0.3205],\n",
    "    crop_size=32,\n",
    "    resize_size=32,\n",
    "    is_training=False\n",
    ")\n",
    "\n",
    "# Load FashionMNIST dataset\n",
    "fashionmnist = FashionMNIST(\n",
    "    data_dir=DATA_DIR,\n",
    "    train=True,\n",
    "    load_into_memory=True\n",
    ")\n",
    "\n",
    "# Prepare dataloaders\n",
    "base_loader = BaseLoader(\n",
    "    dataset=fashionmnist,\n",
    "    main_transform=train_transform,\n",
    "    val_transform=val_transform,\n",
    "    val_split=VAL_SPLIT,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    "    split_seed=SPLIT_SEED,\n",
    "    shuffle_seed=SHUFFLE_SEED\n",
    ")\n",
    "TRAIN_LOADER = base_loader.get_dataloader(mode=\"Main\")\n",
    "VAL_LOADER = base_loader.get_dataloader(mode=\"Val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4f9fad-eb0d-4b95-8d51-8c6362e65caa",
   "metadata": {},
   "source": [
    "### LeNet-5\n",
    "\n",
    "* ``load_pretrained_lenet`` &rarr; Load the pre-trained LeNet-5 network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfc0862-6bba-4c93-a849-156b53f9ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_lenet(\n",
    "    is_training: bool = False\n",
    ") -> nn.Module:\n",
    "    \"\"\"Load the pre-trained LeNet-5 network.\n",
    "\n",
    "    Args:\n",
    "        is_training: If True, the network is set to training mode and\n",
    "          gradients are enabled.  If False, the network is set to\n",
    "          evaluation mode and gradients are disabled.\n",
    "\n",
    "    Returns:\n",
    "        The pre-trained LeNet-5 network.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize network\n",
    "    lenet = LeNet().to(DEVICE)\n",
    "\n",
    "    # Load pre-trained weights\n",
    "    lenet.load_state_dict(\n",
    "        torch.load(\n",
    "            CHKPT_PATH,\n",
    "            map_location=DEVICE,\n",
    "            weights_only=False\n",
    "        )[\"model_state_dict\"]\n",
    "    )\n",
    "\n",
    "    # Set to evaluation mode and disable gradients, if applicable\n",
    "    if not is_training:\n",
    "        lenet.eval()\n",
    "        lenet.requires_grad_(False)\n",
    "    \n",
    "    return lenet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45f9cce-6a0d-43b7-9dc5-83e5fd675762",
   "metadata": {},
   "source": [
    "Next, we initialize the LeNet-5 network with pre-trained weights, and check its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "525ab2d1-2ec4-4295-8d12-f40df0e461de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-10T11:51:52.760200Z",
     "start_time": "2024-09-10T11:51:51.360151Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating LeNet: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 94/94 [00:01<00:00, 75.38batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on validation set after 147 epochs:\n",
      "  Loss: 0.256\n",
      "  Accuracy@1: 0.906\n",
      "  Accuracy@5: 0.999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Criterion used to evaluate classification performance of LeNet-5\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Additional metrics used to evaluate LeNet-5\n",
    "PREDICTION_METRICS = MetricCollection({\n",
    "    \"Accuracy@1\": MulticlassAccuracy(\n",
    "        num_classes=10,\n",
    "        top_k=1,\n",
    "        average=\"micro\",\n",
    "        multidim_average=\"global\"\n",
    "    ),\n",
    "    \"Accuracy@5\": MulticlassAccuracy(\n",
    "        num_classes=10,\n",
    "        top_k=5,\n",
    "        average=\"micro\",\n",
    "        multidim_average=\"global\"\n",
    "    )\n",
    "})\n",
    "\n",
    "# Evaluate performance\n",
    "results = evaluate_classifier(\n",
    "    model=load_pretrained_lenet(),\n",
    "    test_loader=VAL_LOADER,  # same validation set used during training\n",
    "    criterion=criterion,\n",
    "    metrics=PREDICTION_METRICS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Load meta-data from checkpoint\n",
    "epoch_idx = torch.load(\n",
    "    CHKPT_PATH,\n",
    "    map_location=DEVICE,\n",
    "    weights_only=False\n",
    ")[\"epoch_idx\"]\n",
    "output_text = [f\"Results on validation set after {epoch_idx} epochs:\"]\n",
    "\n",
    "# Print results\n",
    "for metric, value in results.items():\n",
    "    output_text.append(f\"{metric}: {value:.3f}\")\n",
    "print(\"\\n  \".join(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd136db1-6658-4772-a16a-0f322c00a5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (7): ReLU()\n",
      "    (8): Rearrange('b c h w -> b (c h w)', c=120, h=1, w=1)\n",
      "    (9): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (10): ReLU()\n",
      "    (11): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(load_pretrained_lenet())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11917473-1b6d-4f4d-ab95-66deb8944ed6",
   "metadata": {},
   "source": [
    "### Training Configuration\n",
    "\n",
    "Next, we specify those parameters of the training configuration ``cfg`` used by the ``RepresentationalSimilarityTrainer``  \n",
    "class that shouldn't change across experiments. **Parameters that have to be set individually for each experiment are**:\n",
    "\n",
    "* hooks.ref\n",
    "* hooks.train\n",
    "* optimizer.params\n",
    "* paths.checkpoints\n",
    "* paths.tensorboard\n",
    "* performance.patience\n",
    "* training.num_epochs\n",
    "\n",
    "**When training is to be resumed from a saved checkpoint**, the following parameter needs to be set as well:\n",
    "\n",
    "* training.resume_from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f32be65d-055f-470d-8fa0-986eeb7e4c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mGeneral configuration\u001b[0m:\n",
      "\n",
      "checkpoints:\n",
      "  delete_previous: true\n",
      "  save_best_model: true\n",
      "  save_frequency: 5\n",
      "dataloader:\n",
      "  batch_size: 128\n",
      "model:\n",
      "  name: lenet\n",
      "optimizer:\n",
      "  name: SGD\n",
      "performance:\n",
      "  dataset: Val\n",
      "  higher_is_better: false\n",
      "  keep_previous_best_score: true\n",
      "  metric: Loss\n",
      "tensorboard:\n",
      "  updates_per_epoch:\n",
      "    Train: 10\n",
      "    Val: 10\n",
      "training:\n",
      "  resume_from: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg_dict = {\n",
    "    \"checkpoints\": {\n",
    "        \"delete_previous\": True,\n",
    "        \"save_best_model\": True,\n",
    "        \"save_frequency\": 5\n",
    "    },\n",
    "    \"dataloader\": {\n",
    "        \"batch_size\": BATCH_SIZE\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"name\": \"lenet\"\n",
    "    },\n",
    "    \"optimizer\": {\n",
    "        \"name\": \"SGD\"\n",
    "    },\n",
    "    \"performance\": {\n",
    "        \"dataset\": \"Val\",\n",
    "        \"higher_is_better\": False,\n",
    "        \"keep_previous_best_score\": True,\n",
    "        \"metric\": \"Loss\"\n",
    "    },\n",
    "    \"tensorboard\": {\n",
    "        \"updates_per_epoch\": {\n",
    "            \"Train\": 10,\n",
    "            \"Val\": 10\n",
    "        }\n",
    "    },\n",
    "    \"training\": {\n",
    "        \"resume_from\": None\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to DictConfig and inspect configuration\n",
    "cfg = OmegaConf.create(cfg_dict)\n",
    "print(f\"\\033[1mGeneral configuration\\033[0m:\\n\\n{OmegaConf.to_yaml(cfg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968650f-026d-47d4-a222-0e43f9b6715c",
   "metadata": {},
   "source": [
    "## RSA\n",
    "\n",
    "\n",
    "### Helper Functions\n",
    "\n",
    "* ``_get_upper_tri_matrix`` &rarr; Extract the upper triangular part of a square matrix.\n",
    "* ``_validate_activations`` &rarr; Validate activations from which to compute an RDM.\n",
    "* ``_is_vector`` &rarr; Check if the input is a ``torch.Tensor`` of dimension 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c07d6f4-4197-4d79-bd72-5d5651e7ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_upper_tri_matrix(A: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"Extract the upper triangular part of a square matrix.\n",
    "\n",
    "    Args:\n",
    "        A: The square matrix from which to extract the upper triangular\n",
    "          matrix (excluding the diagonal).\n",
    "\n",
    "    Returns:\n",
    "        The upper triangular matrix (excluding the diagonal) of the\n",
    "        square matrix ``A``, flattened into a vector using row-major\n",
    "        order.\n",
    "    \"\"\"\n",
    "\n",
    "    mask = torch.triu(torch.ones_like(A, dtype=torch.bool), diagonal=1)\n",
    "    return A[mask]\n",
    "\n",
    "\n",
    "def _validate_activations(activations: torch.Tensor) -> None:\n",
    "    \"\"\"Validate activations from which to compute an RDM.\n",
    "\n",
    "    This function is meant to be called on a matrix of activations from\n",
    "    which to compute an RDM.  Rows of the matrix are associated with\n",
    "    different stimuli, while columns correspond to unit activations.\n",
    "    N stimuli give rise to N * (N - 1) / 2 distinct pairwise distances.\n",
    "    Hence, there should be activations for at least N >= 3 stimuli.\n",
    "\n",
    "    Args:\n",
    "        activations: The matrix of activations from which to compute an\n",
    "          RDM.  Must be a 2-D tensor of size (N, M), where N >= 3 is the\n",
    "          number of stimuli (i.e., the batch size), and M >= 2 is the\n",
    "          number of unit activations per stimulus.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the ``activations`` tensor does not meet the size\n",
    "          and dimensionality requirements stated above.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not isinstance(activations, torch.Tensor):\n",
    "        raise ValueError(\n",
    "            f\"'activations' should be of type torch.Tensor, but is of type {type(activations)}.'\"\n",
    "        )\n",
    "    \n",
    "    if activations.dim() != 2:\n",
    "        raise ValueError(\n",
    "            f\"'activations' should be 2-dimensional, but has {activations.dim()} dimensions.\"\n",
    "        )\n",
    "\n",
    "    if activations.size(dim=0) < 3:\n",
    "        raise ValueError(\n",
    "            \"'activations' should contain activations for at least 3 stimuli.\"\n",
    "        )\n",
    "\n",
    "    if activations.size(dim=1) < 2:\n",
    "        raise ValueError(\n",
    "            \"The number of unit activations per stimulus should be at least 2.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _is_vector(x: torch.Tensor) -> bool:\n",
    "    \"\"\"Check if the input is a ``torch.Tensor`` of dimension 1.\"\"\"\n",
    "    \n",
    "    return isinstance(x, torch.Tensor) and x.dim() == 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b2802-e17e-4ab9-bd93-0ebba2a43337",
   "metadata": {},
   "source": [
    "### Compute RDMs\n",
    "\n",
    "* ``compute_rdm_euclidean`` &rarr; Compute an RDM using Euclidean distance.\n",
    "* ``compute_rdm_correlation`` &rarr; Compute an RDM using (Pearson) correlation distance.\n",
    "* ``compute_rdm`` &rarr; Compute an RDM using the specified method.\n",
    "\n",
    "\n",
    "#### Euclidean Distance\n",
    "\n",
    "We make use of the following identity in the ``compute_rdm_euclidean`` function: For two vectors $\\mathbf{a}$ and $\\mathbf{b}$,  \n",
    "the squared Euclidean distance can be computed as follows:\n",
    "$$\n",
    "\\lVert \\mathbf{a} - \\mathbf{b} \\rVert_2^2 = \\langle \\mathbf{a} - \\mathbf{b}, \\mathbf{a} - \\mathbf{b} \\rangle = \\lVert \\mathbf{a} \\rVert_2^2 + \\lVert \\mathbf{b} \\rVert_2^2 - 2 \\mathbf{a}^{\\top} \\mathbf{b} \\,.\n",
    "$$\n",
    "\n",
    "If $\\mathbf{a} = A_{i,:}^{\\top}$ and $\\mathbf{b} = A_{j,:}^{\\top}$ correspond to two rows of an $N \\times M$ matrix $A$ of activations, this identity becomes\n",
    "$$\n",
    "\\lVert A_{i,:}^{\\top} - A_{j,:}^{\\top} \\rVert_2^2 = \\lVert A_{i,:}^{\\top} \\rVert_2^2 + \\lVert A_{j,:}^{\\top} \\rVert_2^2 - 2 A_{i,:} A_{j,:}^{\\top} = \\lVert A_{i,:}^{\\top} \\rVert_2^2 + \\lVert A_{j,:}^{\\top} \\rVert_2^2 - 2 (A A^{\\top})_{i,j} \\,.\n",
    "$$\n",
    "\n",
    "By defining a vector $\\mathbf{d}$ like so\n",
    "$$\n",
    "\\mathbf{d}_i = \\sum_{m=1}^M A_{i,m}^2 = \\lVert A_{i,:}^{\\top} \\rVert_2^2 \\,, \\quad i = 1, \\ldots, N \\,,\n",
    "$$\n",
    "the squared Euclidean distance between the activations elicited by the $i$-th and $j$-th stimulus, respectively, is given by the  \n",
    "entry in position $(i, j)$ of the matrix\n",
    "$$\n",
    "\\mathbf{d} + \\mathbf{d}^{\\top} - 2 A A^{\\top},\n",
    "$$\n",
    "where the column- and row-vectors $\\mathbf{d}$ and $\\mathbf{d}^{\\top}$, respectively, are broadcast to $N \\times N$-matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10f0b39d-082b-4031-a9f3-58afa3f66d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdm_euclidean(\n",
    "    activations: torch.Tensor,\n",
    "    center_activations: bool = False,\n",
    "    normalize_distances: bool = True,\n",
    "    distance_type: Literal[\"squared\", \"non-squared\"] = \"squared\"\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute an RDM using Euclidean distance.\n",
    "\n",
    "    Note:\n",
    "        This function returns only the upper triangular matrix of the\n",
    "        computed RDM in vectorized form (row-major order).\n",
    "\n",
    "    Args:\n",
    "        activations: The matrix of activations from which to compute the\n",
    "          RDM.  Must be a 2-D tensor of size (N, M), where N >= 3 is the\n",
    "          number of stimuli, and M >= 2 is the number of unit\n",
    "          activations per stimulus.\n",
    "        center_activations: Whether to center the activations for each\n",
    "          stimulus before computing distances.\n",
    "        normalize_distances: Whether to normalize the squared pairwise\n",
    "          distances by the number M of unit activations per stimulus.\n",
    "        distance_type: Whether to return squared or non-squared\n",
    "          distances.\n",
    "\n",
    "    Returns:\n",
    "        The RDM (in vectorized form) computed from the data using\n",
    "        Euclidean distance.\n",
    "    \"\"\"\n",
    "\n",
    "    _validate_activations(activations)\n",
    "\n",
    "    if distance_type not in [\"squared\", \"non-squared\"]:\n",
    "        raise ValueError(\n",
    "            f\"'distance_type' should be either 'squared' or 'non-squared', but got {distance_type}.\"\n",
    "        )\n",
    "\n",
    "    if center_activations:\n",
    "        activations -= activations.mean(dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute squared pairwise distances\n",
    "    norms_squared = torch.sum(torch.square(activations), dim=1, keepdim=True)\n",
    "    distances_squared = norms_squared + norms_squared.T - 2 * torch.mm(activations, activations.T)\n",
    "\n",
    "    # Clamp negative values (potential numerical inaccuracies) and extract RDM\n",
    "    rdm = _get_upper_tri_matrix(torch.clamp(distances_squared, min=0.0))\n",
    "\n",
    "    if normalize_distances:\n",
    "        rdm = rdm / activations.size(dim=1)\n",
    "\n",
    "    if distance_type == \"non-squared\":\n",
    "        rdm = torch.sqrt(rdm)\n",
    "    \n",
    "    return rdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bf061b-2353-4760-8829-3886541c4f89",
   "metadata": {},
   "source": [
    "#### Correlation Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6678e2ad-fd0c-4e21-b591-cfb85459be85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdm_correlation(\n",
    "    activations: torch.Tensor,\n",
    "    center_activations: bool = True\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute an RDM using (Pearson) correlation distance.\n",
    "\n",
    "    Note:\n",
    "        This function returns only the upper triangular matrix of the\n",
    "        computed RDM in vectorized form (row-major order).\n",
    "\n",
    "    Args:\n",
    "        activations: The matrix of activations from which to compute the\n",
    "          RDM.  Must be a 2-D tensor of size (N, M), where N >= 3 is the\n",
    "          number of stimuli, and M >= 2 is the number of unit\n",
    "          activations per stimulus.\n",
    "        center_activations: Whether to center the activations for each\n",
    "          stimulus before computing distances.\n",
    "\n",
    "    Returns:\n",
    "        The RDM (in vectorized form) computed from the data using\n",
    "        (Pearson) correlation distance.\n",
    "    \"\"\"\n",
    "\n",
    "    _validate_activations(activations)\n",
    "\n",
    "    if center_activations:\n",
    "        activations -= activations.mean(dim=1, keepdim=True)\n",
    "\n",
    "    rdm = 1 - _get_upper_tri_matrix(torch.corrcoef(activations))\n",
    "\n",
    "    return rdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85068584-3111-449f-a190-3bbd96a13891",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5be9b958-5cb0-4c20-a0a5-6c1d34d33621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rdm(\n",
    "    activations: torch.Tensor,\n",
    "    method: str,\n",
    "    **kwargs: Any\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compute an RDM using the specified method.\n",
    "\n",
    "    Args:\n",
    "        activations: The matrix of activations from which to compute the\n",
    "        RDM.  Must be a 2-D tensor of size (N, M), where N >= 3 is the\n",
    "          number of stimuli, and M >= 2 is the number of unit\n",
    "          activations per stimulus.\n",
    "        method: The method to use for computing the RDM.\n",
    "        **kwargs: Additional keyword arguments to pass to the specific\n",
    "          function used to compute the RDM.\n",
    "\n",
    "    Returns:\n",
    "        The RDM (in vectorized form) computed from the data using the\n",
    "          specified method.\n",
    "    \"\"\"\n",
    "\n",
    "    methods: Dict[str, Callable[..., torch.Tensor]] = {\n",
    "        \"euclidean\": compute_rdm_euclidean,\n",
    "        \"correlation\": compute_rdm_correlation,\n",
    "    }\n",
    "\n",
    "    if method not in methods:\n",
    "        raise ValueError(\n",
    "            f\"'method' should be one of {list(methods.keys())}, but got {method}.\"\n",
    "        )\n",
    "\n",
    "    return methods[method](activations, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04150aa-7809-4d78-916d-9b208046d091",
   "metadata": {},
   "source": [
    "### Compare RDMs\n",
    "\n",
    "* ``compare_rdm_cosine`` &rarr; Compare two RDMs using cosine similarity.\n",
    "* ``compare_rdm`` &rarr; Compare two RDMs using the specified method.\n",
    "\n",
    "\n",
    "#### Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b70bd576-d4bc-45d2-b53d-622629cdcf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rdm_cosine(\n",
    "    rdm1: torch.Tensor,\n",
    "    rdm2: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compare two RDMs using cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        rdm1: The first RDM in vectorized form.\n",
    "        rdm2: The second RDM in vectorized form.\n",
    "\n",
    "    Returns:\n",
    "        The cosine similarity between the two RDMs.\n",
    "    \"\"\"\n",
    "\n",
    "    if not (_is_vector(rdm1) and _is_vector(rdm2)):\n",
    "        raise ValueError(\n",
    "            \"Both 'rdm1' and 'rdm2' should be tensors of dimension 1.\"\n",
    "        )\n",
    "    \n",
    "    cosine_similarity = torch.dot(rdm1, rdm2) / (\n",
    "        LA.vector_norm(rdm1, ord=2) * LA.vector_norm(rdm2, ord=2)\n",
    "    )\n",
    "    return cosine_similarity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939caa43-871e-4fe7-9508-5212d81fb1a3",
   "metadata": {},
   "source": [
    "#### Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80219f5d-1cd6-4e0c-9cfb-9cc2417a0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_rdm(\n",
    "    rdm1: torch.Tensor,\n",
    "    rdm2: torch.Tensor,\n",
    "    method: str,\n",
    "    **kwargs: Any\n",
    ") -> torch.Tensor:\n",
    "    \"\"\"Compare two RDMs using the specified method.\n",
    "\n",
    "    Args:\n",
    "        rdm1: The first RDM in vectorized form.\n",
    "        rdm2: The second RDM in vectorized form.\n",
    "        method: The method to use for comparing the RDMs.\n",
    "        **kwargs: Additional keyword arguments to pass to the specific\n",
    "          function used to compare the RDMs.\n",
    "\n",
    "    Returns:\n",
    "        The similarity between the two RDMs based on the specified\n",
    "        method.\n",
    "    \"\"\"\n",
    "\n",
    "    methods: dict[str, Callable[..., torch.Tensor]] = {\n",
    "        \"cosine\": compare_rdm_cosine\n",
    "    }\n",
    "\n",
    "    if method not in methods:\n",
    "        raise ValueError(\n",
    "            f\"'method' should be one of {list(methods.keys())}, but got {method}.\"\n",
    "        )\n",
    "\n",
    "    return methods[method](rdm1, rdm2, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5965b52a-bc76-431c-a57a-976a7edfa70f",
   "metadata": {},
   "source": [
    "### Custom Loss\n",
    "\n",
    "* ``rsa_loss`` &rarr; A weighted loss combining cross-entropy and repr. similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4700d68b-a037-486b-82c5-e2db2fc1f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rsa_loss(\n",
    "    predictions: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    activations1: torch.Tensor,\n",
    "    activations2: torch.Tensor,\n",
    "    method_compute: Callable[[torch.Tensor], torch.Tensor],\n",
    "    method_compare: Callable[[torch.Tensor, torch.Tensor], torch.Tensor],\n",
    "    weight_rsa_score: float,\n",
    "    rsa_transform: Optional[Callable[[torch.Tensor], torch.Tensor]] = None\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"A weighted loss combining cross-entropy and repr. similarity.\n",
    "\n",
    "    Note:\n",
    "        Both, the ``method_compute`` and the ``method_compare``\n",
    "        functions should take as arguments only the activations and\n",
    "        RDMs, respectively.  Additional arguments must already be\n",
    "        pre-bound to these functions using the ``partial`` function of\n",
    "        the ``functools`` module.\n",
    "    \n",
    "    Args:\n",
    "        predictions: The model predictions.\n",
    "        targets: The target values.\n",
    "        activations1: First set of activations.  Must be a 2-D tensor of\n",
    "          size (N, M), where N >= 3 is the number of stimuli and M >= 2\n",
    "          is the number of unit activations per stimulus.\n",
    "        activations2: Second set of activations.  Must be a 2-D tensor\n",
    "          of size (N, K), where N >= 3 is the number of stimuli and\n",
    "          K >= 2 is the number of unit activations per stimulus.\n",
    "        method_compute: The method used to compute the RDMs from the\n",
    "          activations.\n",
    "        method_compare: The method used to compare RDMs.\n",
    "        weight_rsa_score: The weight attributed to the (transformed) RSA\n",
    "          score in the weighted loss combination.\n",
    "        rsa_transform: The transformation to apply to the raw RSA score.\n",
    "\n",
    "    Returns:\n",
    "        A tuple consisting of the raw RSA score between the two networks\n",
    "        and the weighted loss.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If ``weight_rsa_score`` is outside the range [0, 1]\n",
    "          or if one of the activation tensors does not meet the size and\n",
    "          dimensionality requirements.\n",
    "    \"\"\"\n",
    "\n",
    "    if not 0 <= weight_rsa_score <= 1:\n",
    "        raise ValueError(\n",
    "            \"'weight_rsa_score' should be a float in the range [0, 1], \"\n",
    "            f\"but got {weight_rsa_score}.\"\n",
    "        )\n",
    "\n",
    "    # Check activation tensors\n",
    "    _validate_activations(activations1)\n",
    "    _validate_activations(activations2)\n",
    "    if activations1.size(dim=0) != activations2.size(dim=0):\n",
    "        raise ValueError(\n",
    "            \"'activations1' and 'activations2' should have the same number of rows.\"\n",
    "        )\n",
    "\n",
    "    # Compute cross-entropy loss\n",
    "    loss = F.cross_entropy(predictions, targets)\n",
    "\n",
    "    # Compute RSA score\n",
    "    rsa_score = method_compare(\n",
    "        method_compute(activations1),\n",
    "        method_compute(activations2)\n",
    "    )\n",
    "\n",
    "    # Transform RSA score & compute weighted loss\n",
    "    rsa_score_transformed = rsa_score if rsa_transform is None else rsa_transform(rsa_score)\n",
    "    weighted_loss = weight_rsa_score * rsa_score_transformed + (1 - weight_rsa_score) * loss\n",
    "    \n",
    "    return rsa_score, weighted_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7a10b3-3f1d-43c6-8564-a95711f886d7",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "\n",
    "### Penultimate Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c29398e3-d47c-4681-9fb8-7d2ae08911b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mConfiguration of Experiment\u001b[0m:\n",
      "\n",
      "checkpoints:\n",
      "  delete_previous: true\n",
      "  save_best_model: true\n",
      "  save_frequency: 5\n",
      "dataloader:\n",
      "  batch_size: 128\n",
      "model:\n",
      "  name: lenet\n",
      "optimizer:\n",
      "  name: SGD\n",
      "  params:\n",
      "    lr: 0.01\n",
      "    momentum: 0.8\n",
      "    dampening: 0\n",
      "    weight_decay: 0.001\n",
      "    nesterov: false\n",
      "    maximize: false\n",
      "    foreach: null\n",
      "    differentiable: false\n",
      "    fused: null\n",
      "performance:\n",
      "  dataset: Val\n",
      "  higher_is_better: false\n",
      "  keep_previous_best_score: true\n",
      "  metric: Loss\n",
      "  patience: null\n",
      "tensorboard:\n",
      "  updates_per_epoch:\n",
      "    Train: 10\n",
      "    Val: 10\n",
      "training:\n",
      "  resume_from: null\n",
      "  num_epochs: 100\n",
      "hooks:\n",
      "  ref: net.10\n",
      "  train: net.10\n",
      "paths:\n",
      "  checkpoints: ../out/lenet_fashionmnist/representational_similarity/test_run/2024-09_13-15-04-37/checkpoints\n",
      "  tensorboard: ../out/lenet_fashionmnist/representational_similarity/test_run/2024-09_13-15-04-37/tensorboard\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                           \r"
     ]
    }
   ],
   "source": [
    "cfg_dict_1 = cfg_dict.copy()\n",
    "\n",
    "# Choose penultimate layer to use for computing RSA scores\n",
    "cfg_dict_1[\"hooks\"] = {\n",
    "    \"ref\": \"net.10\",\n",
    "    \"train\": \"net.10\"\n",
    "}\n",
    "\n",
    "# Set training parameters\n",
    "cfg_dict_1[\"performance\"][\"patience\"] = None\n",
    "cfg_dict_1[\"training\"][\"num_epochs\"] = 100\n",
    "\n",
    "# Instantiate models\n",
    "model_train = load_pretrained_lenet(is_training=True)\n",
    "model_ref = load_pretrained_lenet(is_training=False)\n",
    "\n",
    "# Set up optimizer\n",
    "lr = 0.01\n",
    "momentum = 0.8\n",
    "weight_decay = 1e-3\n",
    "optimizer = torch.optim.SGD(\n",
    "    model_train.parameters(),\n",
    "    lr=lr,\n",
    "    momentum=momentum,\n",
    "    weight_decay=weight_decay\n",
    ")\n",
    "optim_params = optimizer.state_dict()[\"param_groups\"][0]\n",
    "optim_params.pop(\"params\")\n",
    "cfg_dict_1[\"optimizer\"][\"params\"] = optim_params\n",
    "\n",
    "# Set up criterion\n",
    "# NOTE: Cosine similarity returns values between -1 and 1, 0 indicating orthogonality of the two RDMs\n",
    "method_compute = partial(\n",
    "    compute_rdm,\n",
    "    method=\"euclidean\",\n",
    "    center_activations = False,\n",
    "    normalize_distances = True,\n",
    "    distance_type = \"squared\"\n",
    ")\n",
    "method_compare = partial(\n",
    "    compare_rdm,\n",
    "    method=\"cosine\"\n",
    ")\n",
    "rsa_transform = torch.abs\n",
    "weight_rsa_score = 0.8\n",
    "criterion = partial(\n",
    "    rsa_loss,\n",
    "    method_compute=method_compute,\n",
    "    method_compare=method_compare,\n",
    "    weight_rsa_score=weight_rsa_score,\n",
    "    rsa_transform=rsa_transform\n",
    ")\n",
    "\n",
    "# Set paths\n",
    "now = get_timestamp()\n",
    "cfg_dict_1[\"paths\"] = {\n",
    "    \"checkpoints\": f\"../out/lenet_fashionmnist/representational_similarity/test_run/{now}/checkpoints\",\n",
    "    \"tensorboard\": f\"../out/lenet_fashionmnist/representational_similarity/test_run/{now}/tensorboard\"\n",
    "}\n",
    "cfg_1 = OmegaConf.create(cfg_dict_1)\n",
    "\n",
    "# Random seeds\n",
    "set_seeds()\n",
    "\n",
    "# Initialize trainer\n",
    "representational_similarity_trainer = RepresentationalSimilarityTrainer(\n",
    "    model_train=model_train,\n",
    "    model_ref=model_ref,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    train_loader=TRAIN_LOADER,\n",
    "    val_loader=VAL_LOADER,\n",
    "    prediction_metrics=PREDICTION_METRICS,\n",
    "    device=DEVICE,\n",
    "    cfg=cfg_1\n",
    ")\n",
    "\n",
    "# Inspect training configuration & save config file\n",
    "print(f\"\\033[1mConfiguration of Experiment\\033[0m:\\n\\n{OmegaConf.to_yaml(cfg_1)}\")\n",
    "logs_dir = Path(f\"../out/lenet_fashionmnist/representational_similarity/test_run/{now}/logs\")\n",
    "logs_dir.mkdir(parents=True, exist_ok=True)\n",
    "OmegaConf.save(\n",
    "    cfg_1,\n",
    "    logs_dir / \"config.yaml\"\n",
    ")\n",
    "\n",
    "# Start training\n",
    "representational_similarity_trainer.train()\n",
    "\n",
    "# Remove all hooks\n",
    "representational_similarity_trainer.remove_hooks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
