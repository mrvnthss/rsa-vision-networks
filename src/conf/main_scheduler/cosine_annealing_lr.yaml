# https://pytorch.org/docs/2.4/generated/torch.optim.lr_scheduler.CosineAnnealingLR.html
name: CosineAnnealingLR
lr_min: 0

kwargs:
  _target_: torch.optim.lr_scheduler.CosineAnnealingLR
  T_max: null  # automatically set to difference between number of total epochs and warmup epochs
  eta_min: ${main_scheduler.lr_min}
  last_epoch: -1
