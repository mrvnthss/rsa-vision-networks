defaults:
  - criterion: cross_entropy
  - dataset: fashionmnist
  - model: lenet
  - optimizer: sgd
  - _self_
paths:
  data: ../data
  logs: ../logs/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}
  checkpoint: null  # checkpoint to resume training from, null to start training from scratch
hydra:
  run:
    dir: ${paths.logs}
experiment_name: ???
seeds:
  torch: ???
  shuffle_data: ???  # controls shuffling of the training set
  split_data: 42  # controls random splitting of the dataset into training and validation sets
dataloader:
  val_split: 0.15  # fraction of the training set to use as validation set
  batch_size: ???
  num_workers: ???
training:
  num_epochs: 90
metrics:  # empty dict ``{}`` to disable tracking of additional metrics
  Accuracy@1:
    _target_: torchmetrics.classification.MulticlassAccuracy
    num_classes: ${dataset.num_classes}
    top_k: 1
    average: micro
    multidim_average: global
  Accuracy@5:
    _target_: torchmetrics.classification.MulticlassAccuracy
    num_classes: ${dataset.num_classes}
    top_k: 5
    average: micro
    multidim_average: global
performance:
  metric: Loss  # either "Loss" or one of the keys in the ``metrics`` dict
  higher_is_better: False
  dataset: Val  # either "Train" or "Val"
  patience: 10  # null to disable early stopping
  keep_previous_best_score: True
checkpoints:
  dir: ../checkpoints/${experiment_name}/${now:%Y-%m-%d_%H-%M-%S}
  save_frequency: 10  # null to disable regular checkpoint saves
  save_best_model: True
  delete_previous: True
tensorboard:
  updates_per_epoch:
    Train: 10  # null to disable TensorBoard logging during training
    Val: 10  # null to disable TensorBoard logging during validation
