# @package _global_

# This configuration file can be used to run a control experiment on the
# crop ratio parameter used to train the LeNet-5 model on the
# FashionMNIST dataset.
#
# To run this experiment, execute the following command from the
# "thesis-experiments/src/" directory:
#
#   >>> python train_classifier.py experiment=lenet_fashionmnist/data_augmentation/random_cropping_control/ratio
#


# -----------------------
# MULTI-RUN CONFIGURATION
# -----------------------

experiment:
  name: lenet_fashionmnist/data_augmentation/random_cropping_control/ratio
  dir:  ../out/${experiment.name}/${now:%Y-%m-%d_%H-%M-%S}
  sub_dir: crop_scale.lower=${transform.train.crop_scale.lower},crop_ratio.lower=${transform.train.crop_ratio.lower},b=${dataloader.batch_size},momentum=${optimizer.momentum}

paths:
  checkpoints: ${experiment.dir}/${experiment.sub_dir}/checkpoints
  tensorboard: ${experiment.dir}/${experiment.sub_dir}/tensorboard

hydra:
  mode: MULTIRUN
  sweep:
    dir: ${experiment.dir}
    subdir: ${experiment.sub_dir}/logs
  sweeper:
    params:
      transform.train.crop_scale.lower: 0.7, 0.8, 0.9, 1.0  # subset of values from "random_cropping.yaml"
      transform.train.crop_ratio: "{lower: 0.666666666666667, upper: 1.5},{lower: 0.75, upper: 1.3333333333333333},{lower: 0.8, upper: 1.25}"
      dataloader.batch_size: 64, 128  # same as "random_cropping.yaml"
      optimizer.momentum: 0.8, 0.85  # same as "random_cropping.yaml"


# ---------------------
# GENERAL CONFIGURATION
# ---------------------

defaults:
  - override /model: lenet
  - override /dataset: fashionmnist
  - override /transform/train: basic_augmentation
  - _self_

reproducibility:
  torch_seed: 89
  shuffle_seed: 858

training:
  num_epochs: 200  # same as "random_cropping.yaml"

transform:
  train:
    crop_scale:
      upper: 1.0
  val:
    resize_size: ${model.input_size}

dataloader:
  num_workers: 4

optimizer:
  lr: 0.01  # based on "batch_size_lr.yaml"
  weight_decay: 1e-3  # based on "momentum_wd.yaml" & "horizontal_flipping.yaml"

performance:
  patience: 20
